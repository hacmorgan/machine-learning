* Image capture
** Code 
- =image_capture/webcam-capture= captures images as 64 * 48 grayscale images, downsampled from the original 640 * 480 reslution of the webcam.
- These images come as numpy arrays, which are unroled to 1 * 3072 vectors of 8-bit unsigned integers (i.e. they are saved on the interval [0, 255], to be rescaled later)
- A zero is apended to the end of the vector, which represents the classification of that image. This will later be modified by the labelling script.
- Each vector is written to a binary file using numpy's =tobytes()= method. Originally this data was stored in CSV format, but this felt messy.


* Labelling
** Code
- Labelling is done with =labelling/label=, a Tkinter based GUI that shows the image to be labelled, plus the next nine images in a grid.
- Keyboard shortcuts are used to maximise the efficiency of this process.
  - '1' classifies the image as 'record finished' (which is literally stored as a 1), and moves to the next image.
  - '0' classifies the image as 'anything else', and moves to the next image, but this is the default value for the classification so is rarely necessary in pactice.
  - 'n' moves to the next image
  - 'p' moves to the previous image
- The data is imported into a numpy array of size /m * 3073/, for m training examples, which the gui iterates through, and is written to a new file name, again in binary format.


* Training
** Code
- The code to train the network (=training/train=) does not use any neural network libraries. I know this is almost invariably less efficient than using a purpose built, well optimised library; but I just wanted to do it from scratch.
- In its current state, many things are hardcoded (such as the number of layers), and many nice features such as automated stopping are not present. I would like to implement these in the future (more on that below).

** Network
- In its current state, the network is a conventional (i.e. non-convolutional) neural network, with one hiden layer of 30 neurons, and a single output neuron. 
- The network is constructed in a similar manner to those used in Prof. Andrew Ng's online course, where the weights matrices include a row (in this case) of biases, and a neuron that only outputs 1 is added to the first and second layers to multiply these biases.
  - Idk if this is standard, but I have also seen a separate bias vector used.

** Preliminary results
In its current form, the code achieves about 77% accuracy on the test set, with a regularization parameter of 3 and a learning rate of 0.1. In practice, the presence a record at the end of its travel only increased the output neuron's activation from 0.22 to 0.38, quite reliably though.


* Next steps
** Fine-tune this network's parameters to find its optimal performance
** Write SGD function in C
** Try a convolutional network

* Other stuff
** List of records used for training
*** hip-hop
**** 7" singles (and the 10" GE Cypher)
- Trials + K21: Soylent
- Aesop Rock: Klutz
- Golden Era: 2016 Cypher

**** 12" LPs
- Hilltop Hoods: State of the Art
- Wu-Tang Clan: Enter the Wu-Tang
- Brother Ali: The Undisputed Truth
- Plutonic Lab: Deep Above the Noise
- Aesop Rock: The Impossible Kid
- Horrorshow: King Amonst Many
